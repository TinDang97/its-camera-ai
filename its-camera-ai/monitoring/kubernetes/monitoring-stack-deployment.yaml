# Comprehensive Kubernetes Monitoring Stack Deployment
# Production-ready monitoring for ITS Camera AI system
# Supports 1000+ cameras, 10TB/day processing, 99.9% uptime SLA

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    app.kubernetes.io/name: monitoring
    app.kubernetes.io/component: observability

---
# Prometheus Operator CRDs and Operator
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus-operator
  namespace: monitoring

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-operator
rules:
- apiGroups: [""]
  resources: ["nodes", "nodes/metrics", "services", "endpoints", "pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get"]
- apiGroups: ["networking.k8s.io"]
  resources: ["ingresses"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["monitoring.coreos.com"]
  resources: ["*"]
  verbs: ["*"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-operator
subjects:
- kind: ServiceAccount
  name: prometheus-operator
  namespace: monitoring

---
# Production Prometheus Configuration
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus-main
  namespace: monitoring
  labels:
    app: prometheus
    prometheus: main
spec:
  replicas: 3  # High availability setup
  retention: 30d
  retentionSize: 500GB
  
  # Resource allocation for production workload
  resources:
    requests:
      cpu: "4"
      memory: "16Gi"
    limits:
      cpu: "8"
      memory: "32Gi"
  
  # Storage configuration with high-performance SSD
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: fast-ssd
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 500Gi
  
  # Service monitor selector for automatic discovery
  serviceMonitorSelector:
    matchLabels:
      team: its-camera-ai
  
  # Pod monitor selector for direct pod monitoring
  podMonitorSelector:
    matchLabels:
      team: its-camera-ai
  
  # Rule selector for alerting rules
  ruleSelector:
    matchLabels:
      team: its-camera-ai
  
  # Security context
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
  
  # Affinity rules for high availability
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values: [prometheus]
        topologyKey: kubernetes.io/hostname
  
  # Additional Prometheus configuration
  additionalScrapeConfigs:
    name: prometheus-additional-scrape-configs
    key: prometheus-additional.yaml
  
  # Remote write for long-term storage
  remoteWrite:
  - url: "http://thanos-receive:19291/api/v1/receive"
    queueConfig:
      maxSamplesPerSend: 10000
      maxShards: 200
      capacity: 25000
    writeRelabelConfigs:
    - sourceLabels: [__name__]
      regex: '(inference_.*|camera_.*|its_camera_ai_.*|up|node_.*|DCGM_.*|postgresql_.*|redis_.*|kafka_.*)'
      action: keep
  
  # Alertmanager configuration
  alerting:
    alertmanagers:
    - namespace: monitoring
      name: alertmanager-main
      port: web

---
# Service Monitor for ITS Camera AI Services
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: its-camera-ai-services
  namespace: monitoring
  labels:
    team: its-camera-ai
    app: its-camera-ai
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: its-camera-ai
  endpoints:
  - port: metrics
    interval: 15s
    path: /metrics
    honorLabels: true
  - port: business-metrics
    interval: 30s
    path: /business/metrics
    honorLabels: true
  namespaceSelector:
    matchNames:
    - its-camera-ai-production
    - its-camera-ai-staging

---
# Pod Monitor for GPU Metrics
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: gpu-monitoring
  namespace: monitoring
  labels:
    team: its-camera-ai
    component: gpu
spec:
  selector:
    matchLabels:
      app: dcgm-exporter
  podMetricsEndpoints:
  - port: dcgm
    interval: 10s
    path: /metrics
  namespaceSelector:
    matchNames:
    - its-camera-ai-production
    - monitoring

---
# Grafana Deployment with Production Configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 2
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      serviceAccountName: grafana
      securityContext:
        runAsUser: 472
        runAsGroup: 472
        fsGroup: 472
        runAsNonRoot: true
      containers:
      - name: grafana
        image: grafana/grafana:10.2.3
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-credentials
              key: admin-password
        - name: GF_DATABASE_TYPE
          value: postgres
        - name: GF_DATABASE_HOST
          value: postgresql-cluster-rw.its-camera-ai-production:5432
        - name: GF_DATABASE_NAME
          value: grafana
        - name: GF_DATABASE_USER
          value: grafana
        - name: GF_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-db-credentials
              key: password
        - name: GF_DATABASE_SSL_MODE
          value: require
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel,grafana-worldmap-panel,grafana-clock-panel,grafana-polystat-panel"
        - name: GF_FEATURE_TOGGLES_ENABLE
          value: "ngalert,live,correlations,datasourceQueryMultiStatus"
        - name: GF_UNIFIED_ALERTING_ENABLED
          value: "true"
        - name: GF_ALERTING_ENABLED
          value: "false"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1
            memory: 2Gi
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-datasources
          mountPath: /etc/grafana/provisioning/datasources
        - name: grafana-dashboards-config
          mountPath: /etc/grafana/provisioning/dashboards
        - name: grafana-dashboards
          mountPath: /var/lib/grafana/dashboards
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 30
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-storage
      - name: grafana-datasources
        configMap:
          name: grafana-datasources
      - name: grafana-dashboards-config
        configMap:
          name: grafana-dashboards-config
      - name: grafana-dashboards
        configMap:
          name: grafana-dashboards

---
# Grafana Service Account and RBAC
apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana
  namespace: monitoring

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana
rules:
- apiGroups: [""]
  resources: ["nodes", "nodes/proxy", "nodes/metrics", "services", "endpoints", "pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources: ["ingresses"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: grafana
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana
subjects:
- kind: ServiceAccount
  name: grafana
  namespace: monitoring

---
# AlertManager with High Availability
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: alertmanager-main
  namespace: monitoring
  labels:
    app: alertmanager
spec:
  replicas: 3
  retention: 120h
  
  # Resource allocation
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi
  
  # Storage configuration
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: fast-ssd
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 20Gi
  
  # Security context
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
  
  # Affinity rules
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values: [alertmanager]
        topologyKey: kubernetes.io/hostname

---
# Loki for Log Aggregation
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: monitoring
  labels:
    app: loki
spec:
  serviceName: loki
  replicas: 3
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      serviceAccountName: loki
      securityContext:
        runAsUser: 10001
        runAsGroup: 10001
        fsGroup: 10001
        runAsNonRoot: true
      containers:
      - name: loki
        image: grafana/loki:2.9.4
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9095
          name: grpc
        args:
        - "-config.file=/etc/loki/local-config.yaml"
        - "-target=all"
        - "-server.http-listen-port=3100"
        - "-server.grpc-listen-port=9095"
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki
        - name: loki-storage
          mountPath: /loki
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 15
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 30
          periodSeconds: 30
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: loki-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: fast-ssd
      resources:
        requests:
          storage: 200Gi

---
# Jaeger for Distributed Tracing
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger-all-in-one
  namespace: monitoring
  labels:
    app: jaeger
spec:
  replicas: 2
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:1.51
        ports:
        - containerPort: 16686
          name: ui
        - containerPort: 14268
          name: http-collector
        - containerPort: 14250
          name: grpc-collector
        - containerPort: 9411
          name: zipkin
        env:
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        - name: SPAN_STORAGE_TYPE
          value: elasticsearch
        - name: ES_SERVER_URLS
          value: "http://elasticsearch:9200"
        - name: ES_USERNAME
          value: "jaeger"
        - name: ES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: jaeger-elasticsearch-credentials
              key: password
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1
            memory: 2Gi

---
# OpenTelemetry Collector Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: monitoring
  labels:
    app: otel-collector
spec:
  replicas: 3
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      serviceAccountName: otel-collector
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:0.89.0
        ports:
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 8888
          name: metrics
        - containerPort: 8889
          name: prometheus
        - containerPort: 13133
          name: health
        args:
        - "--config=/etc/otelcol-contrib/otel-collector.yaml"
        volumeMounts:
        - name: otel-collector-config
          mountPath: /etc/otelcol-contrib
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1
            memory: 2Gi
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 15
          periodSeconds: 10
      volumes:
      - name: otel-collector-config
        configMap:
          name: otel-collector-config

---
# DCGM Exporter for GPU Monitoring
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: dcgm-exporter
  namespace: monitoring
  labels:
    app: dcgm-exporter
spec:
  selector:
    matchLabels:
      app: dcgm-exporter
  template:
    metadata:
      labels:
        app: dcgm-exporter
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9400"
        prometheus.io/path: "/metrics"
    spec:
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      nodeSelector:
        accelerator: nvidia-tesla-v100
      hostNetwork: true
      hostPID: true
      containers:
      - name: dcgm-exporter
        image: nvcr.io/nvidia/k8s/dcgm-exporter:3.2.5-3.1.8-ubuntu20.04
        ports:
        - containerPort: 9400
          name: dcgm
        securityContext:
          runAsNonRoot: false
          runAsUser: 0
          capabilities:
            add: ["SYS_ADMIN"]
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys

---
# Services for Monitoring Stack
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  selector:
    app.kubernetes.io/name: prometheus
  ports:
  - port: 9090
    targetPort: 9090
    name: web
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
    name: http
  type: LoadBalancer
  loadBalancerSourceRanges:
  - "10.0.0.0/8"  # Restrict access to internal networks

---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
spec:
  selector:
    app.kubernetes.io/name: alertmanager
  ports:
  - port: 9093
    targetPort: 9093
    name: web
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: monitoring
  labels:
    app: loki
spec:
  selector:
    app: loki
  ports:
  - port: 3100
    targetPort: 3100
    name: http
  - port: 9095
    targetPort: 9095
    name: grpc
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-query
  namespace: monitoring
  labels:
    app: jaeger
spec:
  selector:
    app: jaeger
  ports:
  - port: 16686
    targetPort: 16686
    name: ui
  type: LoadBalancer

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-collector
  namespace: monitoring
  labels:
    app: jaeger
spec:
  selector:
    app: jaeger
  ports:
  - port: 14268
    targetPort: 14268
    name: http-collector
  - port: 14250
    targetPort: 14250
    name: grpc-collector
  - port: 9411
    targetPort: 9411
    name: zipkin
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: monitoring
  labels:
    app: otel-collector
spec:
  selector:
    app: otel-collector
  ports:
  - port: 4317
    targetPort: 4317
    name: otlp-grpc
  - port: 4318
    targetPort: 4318
    name: otlp-http
  - port: 8888
    targetPort: 8888
    name: metrics
  - port: 8889
    targetPort: 8889
    name: prometheus
  type: ClusterIP

---
# Persistent Volume Claims
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-storage
  namespace: monitoring
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 50Gi

---
# Network Policies for Security
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: monitoring-network-policy
  namespace: monitoring
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: its-camera-ai-production
    - namespaceSelector:
        matchLabels:
          name: its-camera-ai-staging
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090  # Prometheus
    - protocol: TCP
      port: 3000  # Grafana
    - protocol: TCP
      port: 9093  # AlertManager
    - protocol: TCP
      port: 3100  # Loki
    - protocol: TCP
      port: 16686 # Jaeger UI
    - protocol: TCP
      port: 4317  # OTLP gRPC
    - protocol: TCP
      port: 4318  # OTLP HTTP
  egress:
  - {}  # Allow all egress for external integrations