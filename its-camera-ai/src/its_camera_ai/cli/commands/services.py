"""Service management commands for ITS Camera AI.

Commands for starting, stopping, and managing various system services.
"""

import asyncio
import time

import typer
import uvicorn
from rich.live import Live
from rich.table import Table

from ...core.config import get_settings
from ...core.logging import setup_logging
from ...services.streaming_container import (
    get_streaming_server,
    initialize_streaming_container,
)

# from ..backend.orchestrator import ServiceOrchestrator  # Avoid circular import
from ..backend.service_discovery import ServiceDiscovery
from ..utils import (
    console,
    create_progress,
    create_status_table,
    format_duration,
    get_status_style,
    handle_async_command,
    print_error,
    print_info,
    print_success,
)

app = typer.Typer(help="ðŸš€ Service management commands")


@app.command()
def start(
    service: str | None = typer.Argument(
        None, help="Specific service to start (api, inference, monitoring)"
    ),
    host: str = typer.Option(
        "127.0.0.1", "--host", "-h", help="Host to bind the API server to"
    ),
    port: int = typer.Option(
        8080, "--port", "-p", help="Port to bind the API server to"
    ),
    workers: int = typer.Option(
        1, "--workers", "-w", help="Number of worker processes for API"
    ),
    reload: bool = typer.Option(
        False, "--reload", "-r", help="Enable auto-reload for development"
    ),
    detach: bool = typer.Option(
        False, "--detach", "-d", help="Run services in background"
    ),
) -> None:
    """ðŸš€ Start system services.

    Start one or all system services including API server, inference engine,
    and monitoring services.
    """
    settings = get_settings()
    setup_logging(settings)

    services_to_start = [service] if service else ["api", "inference", "monitoring"]

    with create_progress() as progress:
        task = progress.add_task("Starting services...", total=len(services_to_start))

        for svc in services_to_start:
            progress.update(task, description=f"Starting {svc} service...")

            if svc == "api":
                _start_api_service(host, port, workers, reload, detach)
            elif svc == "inference":
                _start_inference_service(detach)
            elif svc == "monitoring":
                _start_monitoring_service(detach)
            else:
                print_error(f"Unknown service: {svc}")

            progress.advance(task)

    print_success(f"Started {', '.join(services_to_start)} service(s)")


def _start_api_service(
    host: str, port: int, workers: int, reload: bool, detach: bool
) -> None:
    """
    Start the FastAPI server.

    Args:
        host: Host to bind to
        port: Port to bind to
        workers: Number of workers
        reload: Enable auto-reload
        detach: Run in background
    """
    print_info(f"Starting API server on {host}:{port}")

    if detach:
        print_info("Background mode not implemented yet - running in foreground")

    try:
        uvicorn.run(
            "its_camera_ai.api.main:app",
            host=host,
            port=port,
            workers=1 if reload else workers,
            reload=reload,
            log_level="info",
            access_log=True,
        )
    except Exception as e:
        print_error(f"Failed to start API server: {e}")


def _start_inference_service(detach: bool) -> None:
    """
    Start the ML inference service.

    Args:
        detach: Run in background
    """
    print_info("Starting ML inference service")

    # Implementation would start the actual inference service
    # For now, just simulate
    if detach:
        print_info("Inference service would start in background")
    else:
        print_info("Inference service would start in foreground")


def _start_monitoring_service(detach: bool) -> None:
    """
    Start the monitoring service.

    Args:
        detach: Run in background
    """
    print_info("Starting monitoring service")

    # Implementation would start Prometheus, Grafana, etc.
    # For now, just simulate
    if detach:
        print_info("Monitoring service would start in background")
    else:
        print_info("Monitoring service would start in foreground")


@app.command()
def stop(
    service: str | None = typer.Argument(
        None, help="Specific service to stop (api, inference, monitoring)"
    ),
    force: bool = typer.Option(False, "--force", "-f", help="Force stop services"),
) -> None:
    """â¹ï¸ Stop system services.

    Stop one or all running system services gracefully, or force stop if needed.
    """
    services_to_stop = [service] if service else ["api", "inference", "monitoring"]

    with create_progress() as progress:
        task = progress.add_task("Stopping services...", total=len(services_to_stop))

        for svc in services_to_stop:
            progress.update(task, description=f"Stopping {svc} service...")

            # Implementation would actually stop the services
            # For now, just simulate
            time.sleep(0.5)

            progress.advance(task)

    action = "Force stopped" if force else "Stopped"
    print_success(f"{action} {', '.join(services_to_stop)} service(s)")


@app.command()
def restart(
    service: str | None = typer.Argument(
        None, help="Specific service to restart (api, inference, monitoring)"
    ),
    force: bool = typer.Option(False, "--force", "-f", help="Force restart services"),
) -> None:
    """ðŸ”„ Restart system services.

    Restart one or all system services. This will stop and then start services.
    """
    services_to_restart = [service] if service else ["api", "inference", "monitoring"]

    with create_progress() as progress:
        total_steps = len(services_to_restart) * 2  # Stop + Start
        task = progress.add_task("Restarting services...", total=total_steps)

        # Stop services
        for svc in services_to_restart:
            progress.update(task, description=f"Stopping {svc} service...")
            time.sleep(0.5)  # Simulate stop
            progress.advance(task)

        # Start services
        for svc in services_to_restart:
            progress.update(task, description=f"Starting {svc} service...")
            time.sleep(0.5)  # Simulate start
            progress.advance(task)

    action = "Force restarted" if force else "Restarted"
    print_success(f"{action} {', '.join(services_to_restart)} service(s)")


@app.command()
@handle_async_command
async def status(
    watch: bool = typer.Option(
        False, "--watch", "-w", help="Watch status in real-time"
    ),
    interval: int = typer.Option(
        5, "--interval", "-i", help="Update interval in seconds for watch mode"
    ),
) -> None:
    """ðŸ“‹ Show service status.

    Display the current status of all system services including health,
    uptime, and performance metrics.
    """
    if watch:
        await _watch_status(interval)
    else:
        await _show_status_once()


async def _show_status_once() -> None:
    """
    Show service status once.
    """
    table = create_status_table()

    # Get actual service status (simulated for now)
    services = await _get_service_status()

    for service in services:
        status_style = get_status_style(service["status"])
        health_style = get_status_style(service["health"])

        table.add_row(
            service["name"],
            f"[{status_style}]{service['status']}[/{status_style}]",
            f"[{health_style}]{service['health']}[/{health_style}]",
            service["uptime"],
            service["details"],
        )

    console.print(table)


async def _watch_status(interval: int) -> None:
    """
    Watch service status in real-time.

    Args:
        interval: Update interval in seconds
    """
    try:
        with Live(auto_refresh=False) as live:
            while True:
                table = create_status_table()

                services = await _get_service_status()

                for service in services:
                    status_style = get_status_style(service["status"])
                    health_style = get_status_style(service["health"])

                    table.add_row(
                        service["name"],
                        f"[{status_style}]{service['status']}[/{status_style}]",
                        f"[{health_style}]{service['health']}[/{health_style}]",
                        service["uptime"],
                        service["details"],
                    )

                live.update(table)
                live.refresh()

                await asyncio.sleep(interval)

    except KeyboardInterrupt:
        print_info("Status monitoring stopped")


async def _get_service_status() -> list[dict]:
    """
    Get current service status.

    Returns:
        List of service status dictionaries
    """
    # This would integrate with actual service monitoring
    # For now, return simulated data
    import random

    services = [
        {
            "name": "API Server",
            "status": random.choice(["Running", "Starting", "Stopped"]),
            "health": random.choice(["Healthy", "Warning", "Critical"]),
            "uptime": format_duration(random.randint(0, 86400)),
            "details": f"Port 8080, {random.randint(1, 4)} workers",
        },
        {
            "name": "Inference Engine",
            "status": random.choice(["Running", "Loading", "Stopped"]),
            "health": random.choice(["Healthy", "Warning"]),
            "uptime": format_duration(random.randint(0, 3600)),
            "details": f"GPU: {random.randint(20, 80)}% utilization",
        },
        {
            "name": "Monitoring",
            "status": random.choice(["Running", "Stopped"]),
            "health": random.choice(["Healthy", "Warning"]),
            "uptime": format_duration(random.randint(0, 7200)),
            "details": f"Metrics: {random.randint(100, 1000)}/min",
        },
        {
            "name": "Database",
            "status": "Running",
            "health": "Healthy",
            "uptime": format_duration(random.randint(86400, 604800)),
            "details": f"Connections: {random.randint(5, 20)}/50",
        },
        {
            "name": "Redis Cache",
            "status": "Running",
            "health": "Healthy",
            "uptime": format_duration(random.randint(3600, 86400)),
            "details": f"Memory: {random.randint(10, 90)}% used",
        },
    ]

    return services


@app.command()
@handle_async_command
async def discover(
    _register: bool = typer.Option(
        False, "--register", "-r", help="Register discovered services"
    ),
    monitor: bool = typer.Option(
        False, "--monitor", "-m", help="Start continuous monitoring"
    ),
) -> None:
    """ðŸ” Discover backend services.

    Discover available backend services and optionally register them
    for monitoring and health checks.
    """
    try:
        async with ServiceDiscovery() as service_discovery:
            print_info("Discovering backend services...")

            discovered_count = await service_discovery.discover_services()
            print_success(f"Discovered {discovered_count} services")

            # Get service status
            services_status = await service_discovery.get_all_services_status()

            # Display discovered services
            table = Table(title="ðŸ” Discovered Services")
            table.add_column("Service", style="cyan")
            table.add_column("Type", style="blue")
            table.add_column("URL", style="green")
            table.add_column("Status", style="bold")
            table.add_column("Response Time", style="yellow")

            for service_name, status_data in services_status.items():
                service_type = status_data.get("type", "unknown")
                url = status_data.get("url", "N/A")
                is_healthy = status_data.get("is_healthy", False)
                response_time = status_data.get("response_time_ms")

                status_text = "Healthy" if is_healthy else "Unhealthy"
                status_color = "green" if is_healthy else "red"
                response_time_text = (
                    f"{response_time:.2f}ms" if response_time else "N/A"
                )

                table.add_row(
                    service_name,
                    service_type,
                    url[:50] + "..." if len(url) > 50 else url,
                    f"[{status_color}]{status_text}[/{status_color}]",
                    response_time_text,
                )

            console.print(table)

            if monitor:
                print_info("Starting continuous service monitoring...")
                await service_discovery.start_monitoring()

                try:
                    # Keep monitoring until interrupted
                    while True:
                        await asyncio.sleep(30)
                        print_info("Monitoring services... (Ctrl+C to stop)")
                except KeyboardInterrupt:
                    print_info("Stopping service monitoring")
                finally:
                    await service_discovery.stop_monitoring()

    except Exception as e:
        print_error(f"Service discovery failed: {e}")


@app.command()
@handle_async_command
async def orchestrate(
    operation: str = typer.Argument(
        help="Operation to orchestrate (health-check, start-monitoring, maintenance)"
    ),
    detailed: bool = typer.Option(
        False, "--detailed", "-d", help="Show detailed output"
    ),
) -> None:
    """ðŸŽ­ Orchestrate complex backend operations.

    Coordinate complex multi-service operations using the service orchestrator.
    Available operations: health-check, start-monitoring, stop-monitoring, maintenance
    """
    try:
        # ServiceOrchestrator not yet implemented, using placeholder
        orchestrator = {
            "health_check": lambda: {
                "overall_status": "healthy",
                "components": {},
                "summary": {
                    "health_score": 100,
                    "total_components": 0,
                    "healthy_count": 0,
                },
            }
        }
        if True:  # placeholder for orchestrator context
            if operation == "health-check":
                print_info("Running comprehensive system health check...")

                with create_progress() as progress:
                    task = progress.add_task("Health check in progress...", total=100)

                    health_result = orchestrator["health_check"]()
                    progress.update(task, completed=100)

                # Display results
                overall_status = health_result["overall_status"]
                if overall_status == "healthy":
                    print_success(f"âœ… System health check completed: {overall_status}")
                elif overall_status == "degraded":
                    console.print(
                        f"[yellow]âš ï¸ System health check completed: {overall_status}[/yellow]"
                    )
                else:
                    print_error(f"âŒ System health check completed: {overall_status}")

                if detailed:
                    # Show component details
                    console.print("\n[bold]Component Details:[/bold]")
                    for component, result in health_result["components"].items():
                        status_color = (
                            "green" if result["status"] == "healthy" else "red"
                        )
                        console.print(
                            f"  â€¢ {component}: [{status_color}]{result['status']}[/{status_color}] - {result['message']}"
                        )

                    # Show summary
                    summary = health_result["summary"]
                    console.print("\n[bold]Summary:[/bold]")
                    console.print(f"  â€¢ Health Score: {summary['health_score']}%")
                    console.print(
                        f"  â€¢ Components: {summary['total_components']} total, {summary['healthy_count']} healthy"
                    )

            elif operation == "start-monitoring":
                print_info("Starting all monitoring services...")

                result = await orchestrator.start_monitoring_services()

                if result["status"] == "success":
                    print_success("âœ… All monitoring services started")
                    if detailed:
                        for service, status in result["services"].items():
                            console.print(f"  â€¢ {service}: {status}")
                else:
                    print_error("âŒ Failed to start monitoring services")

            elif operation == "stop-monitoring":
                print_info("Stopping all monitoring services...")

                result = await orchestrator.stop_monitoring_services()

                if result["status"] == "success":
                    print_success("âœ… All monitoring services stopped")
                    if detailed:
                        for service, status in result["services"].items():
                            console.print(f"  â€¢ {service}: {status}")
                else:
                    print_error("âŒ Failed to stop monitoring services")

            elif operation == "maintenance":
                print_info("Running system maintenance...")

                maintenance_ops = [
                    "cleanup_database",
                    "vacuum_database",
                    "clear_caches",
                    "health_check",
                ]

                with create_progress() as progress:
                    task = progress.add_task("Maintenance in progress...", total=100)

                    result = await orchestrator.perform_system_maintenance(
                        maintenance_ops
                    )
                    progress.update(task, completed=100)

                if result["status"] == "success":
                    print_success(
                        f"âœ… Maintenance completed: {result['operations_completed']} operations"
                    )

                    if detailed:
                        console.print("\n[bold]Maintenance Results:[/bold]")
                        for operation, op_result in result["results"].items():
                            console.print(f"  â€¢ {operation}: {op_result}")
                else:
                    print_error("âŒ Maintenance failed")

            else:
                print_error(f"Unknown operation: {operation}")
                console.print(
                    "Available operations: health-check, start-monitoring, stop-monitoring, maintenance"
                )

    except Exception as e:
        print_error(f"Operation failed: {e}")


@app.command()
@handle_async_command
async def overview() -> None:
    """ðŸ“Š Show comprehensive system overview.

    Display a comprehensive overview of all backend services,
    their status, and key metrics.
    """
    try:
        # ServiceOrchestrator not yet implemented, using placeholder
        orchestrator = {
            "get_system_overview": lambda: {
                "orchestrator": {
                    "initialized": True,
                    "services_started": [],
                    "active_operations": 0,
                },
                "api_client": {
                    "connected": False,
                    "base_url": "N/A",
                    "circuit_open": False,
                    "cache_entries": 0,
                },
                "auth_manager": {"authenticated": False},
                "database": {"connected": False},
                "service_discovery": {
                    "connected": False,
                    "event_handlers": {},
                    "buffer_size": 0,
                },
                "queue_manager": {
                    "initialized": False,
                    "configured_queues": [],
                    "registered_handlers": [],
                },
                "metrics_collector": {
                    "collecting": False,
                    "total_series": 0,
                    "total_points": 0,
                    "memory_usage_mb": 0.0,
                },
            }
        }
        if True:  # placeholder for orchestrator context
            print_info("Gathering system overview...")

            # Get system overview
            overview = orchestrator["get_system_overview"]()

            # Display orchestrator status
            console.print("\n[bold]ðŸŽ­ Orchestrator Status[/bold]")
            console.print(
                f"  â€¢ Initialized: {'âœ…' if overview['orchestrator']['initialized'] else 'âŒ'}"
            )
            console.print(
                f"  â€¢ Services Started: {len(overview['orchestrator']['services_started'])}"
            )
            console.print(
                f"  â€¢ Active Operations: {overview['orchestrator']['active_operations']}"
            )

            # Display API client status
            api_stats = overview["api_client"]
            console.print("\n[bold]ðŸŒ API Client Status[/bold]")
            console.print(f"  â€¢ Connected: {'âœ…' if api_stats['connected'] else 'âŒ'}")
            console.print(f"  â€¢ Base URL: {api_stats['base_url']}")
            console.print(
                f"  â€¢ Circuit Open: {'âš ï¸' if api_stats['circuit_open'] else 'âœ…'}"
            )
            console.print(f"  â€¢ Cache Entries: {api_stats['cache_entries']}")

            # Display authentication status
            auth_info = overview["auth_manager"]
            console.print("\n[bold]ðŸ” Authentication Status[/bold]")
            console.print(
                f"  â€¢ Authenticated: {'âœ…' if auth_info['authenticated'] else 'âŒ'}"
            )
            if auth_info.get("current_user"):
                console.print(
                    f"  â€¢ Current User: {auth_info['current_user'].get('username', 'Unknown')}"
                )

            # Display database status
            db_info = overview["database"]
            console.print("\n[bold]ðŸ—„ï¸ Database Status[/bold]")
            console.print(f"  â€¢ Connected: {'âœ…' if db_info['connected'] else 'âŒ'}")

            # Display service discovery status
            discovery_info = overview["service_discovery"]
            console.print("\n[bold]ðŸ” Service Discovery Status[/bold]")
            console.print(
                f"  â€¢ Connected: {'âœ…' if discovery_info['connected'] else 'âŒ'}"
            )
            console.print(
                f"  â€¢ Event Handlers: {sum(discovery_info['event_handlers'].values())}"
            )
            console.print(f"  â€¢ Buffer Size: {discovery_info['buffer_size']}")

            # Display queue manager status
            queue_info = overview["queue_manager"]
            console.print("\n[bold]ðŸ“‹ Queue Manager Status[/bold]")
            console.print(
                f"  â€¢ Initialized: {'âœ…' if queue_info['initialized'] else 'âŒ'}"
            )
            console.print(
                f"  â€¢ Configured Queues: {len(queue_info['configured_queues'])}"
            )
            console.print(
                f"  â€¢ Registered Handlers: {len(queue_info['registered_handlers'])}"
            )

            # Display metrics collector status
            metrics_info = overview["metrics_collector"]
            console.print("\n[bold]ðŸ“ˆ Metrics Collector Status[/bold]")
            console.print(
                f"  â€¢ Collecting: {'âœ…' if metrics_info['collecting'] else 'âŒ'}"
            )
            console.print(f"  â€¢ Total Series: {metrics_info['total_series']}")
            console.print(f"  â€¢ Total Points: {metrics_info['total_points']}")
            console.print(f"  â€¢ Memory Usage: {metrics_info['memory_usage_mb']:.2f} MB")

    except Exception as e:
        print_error(f"Failed to get system overview: {e}")


@app.command()
def logs(
    service: str | None = typer.Argument(
        None, help="Service to show logs for (api, inference, monitoring)"
    ),
    follow: bool = typer.Option(
        False, "--follow", "-f", help="Follow log output in real-time"
    ),
    lines: int = typer.Option(
        100, "--lines", "-n", help="Number of lines to show from end of logs"
    ),
    _level: str | None = typer.Option(
        None,
        "--level",
        "-l",
        help="Filter logs by level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
    ),
) -> None:
    """ðŸ“œ Show service logs.

    Display logs for specific services or all services. Can follow logs
    in real-time and filter by log level.
    """
    service_name = service or "all services"

    if follow:
        print_info(f"Following logs for {service_name} (Ctrl+C to stop)")
        # Implementation would tail actual log files
        try:
            while True:
                # Simulate log output
                console.print(
                    f"[dim]{time.strftime('%Y-%m-%d %H:%M:%S')}[/dim] [blue]INFO[/blue] Sample log entry for {service_name}"
                )
                time.sleep(1)
        except KeyboardInterrupt:
            print_info("Log following stopped")
    else:
        print_info(f"Showing last {lines} log lines for {service_name}")
        # Implementation would read actual log files
        for i in range(min(lines, 20)):  # Simulate some log entries
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            level_color = "blue" if i % 2 == 0 else "yellow"
            log_level = "INFO" if i % 2 == 0 else "WARNING"
            console.print(
                f"[dim]{timestamp}[/dim] [{level_color}]{log_level}[/{level_color}] Sample log entry {i + 1} for {service_name}"
            )


@app.command()
@handle_async_command
async def health(
    service: str | None = typer.Argument(None, help="Service to check health for"),
    _verbose: bool = typer.Option(
        False, "--verbose", "-v", help="Show detailed health information"
    ),
) -> None:
    """â¤ï¸ Check service health.

    Perform health checks on services and display detailed health status.
    """
    services_to_check = (
        [service] if service else ["api", "database", "redis", "inference"]
    )

    table = Table(title="Health Check Results")
    table.add_column("Service", style="cyan")
    table.add_column("Status", style="green")
    table.add_column("Response Time", style="yellow")
    table.add_column("Details", style="dim")

    with create_progress() as progress:
        task = progress.add_task(
            "Running health checks...", total=len(services_to_check)
        )

        for svc in services_to_check:
            progress.update(task, description=f"Checking {svc}...")

            # Simulate health check
            await asyncio.sleep(0.5)

            # Get health status (simulated)
            import random

            response_time = random.randint(1, 100)
            is_healthy = random.choice(
                [True, True, True, False]
            )  # 75% chance of healthy

            status = "Healthy" if is_healthy else "Unhealthy"
            status_style = "green" if is_healthy else "red"
            details = "All checks passed" if is_healthy else "Connection timeout"

            table.add_row(
                svc.title(),
                f"[{status_style}]{status}[/{status_style}]",
                f"{response_time}ms",
                details,
            )

            progress.advance(task)

    console.print(table)

    # Show summary
    healthy_count = len(
        [svc for svc in services_to_check if True]
    )  # Simulate all healthy
    total_count = len(services_to_check)

    if healthy_count == total_count:
        print_success(f"All {total_count} services are healthy")
    else:
        print_error(
            f"{total_count - healthy_count} of {total_count} services are unhealthy"
        )


@app.command()
def streaming(
    host: str = typer.Option("127.0.0.1", "--host", "-h", help="gRPC server host"),
    port: int = typer.Option(50051, "--port", "-p", help="gRPC server port"),
    redis_url: str = typer.Option(
        "redis://localhost:6379", "--redis", "-r", help="Redis connection URL"
    ),
    max_streams: int = typer.Option(
        100, "--max-streams", "-m", help="Maximum concurrent camera streams"
    ),
    debug: bool = typer.Option(False, "--debug", "-d", help="Enable debug logging"),
) -> None:
    """ðŸ“¹ Start the streaming service for camera frame processing.

    The streaming service provides gRPC endpoints for:
    - Camera stream registration
    - Real-time frame processing
    - Quality validation
    - Batch processing
    - Health monitoring

    Performance targets:
    - Support 100+ concurrent camera streams
    - Frame processing latency < 10ms
    - 99.9% frame processing success rate
    """
    import logging

    if debug:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    print_info(f"ðŸš€ Starting ITS Camera AI Streaming Service on {host}:{port}")
    print_info(f"ðŸ“Š Redis connection: {redis_url}")
    print_info(f"ðŸ“¹ Max concurrent streams: {max_streams}")

    # Initialize container with configuration
    config = {
        "redis": {"url": redis_url},
        "streaming": {
            "grpc_host": host,
            "grpc_port": port,
            "max_concurrent_streams": max_streams,
        },
    }

    try:
        initialize_streaming_container(config)
        streaming_server = get_streaming_server()

        print_success("âœ… Streaming service dependencies initialized")

        # Run the server
        handle_async_command(streaming_server.serve_forever())

    except KeyboardInterrupt:
        print_info("ðŸ›‘ Received shutdown signal")
    except Exception as e:
        print_error(f"âŒ Streaming service failed: {e}")
        raise typer.Exit(1) from e
    finally:
        print_info("ðŸ”„ Streaming service stopped")
